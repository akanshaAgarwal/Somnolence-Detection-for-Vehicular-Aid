{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import dlib\n",
    "import sys\n",
    "import skimage \n",
    "from PIL import Image\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouth_extraction(image,count):\n",
    "    data = []\n",
    "    data.append(image)\n",
    "    data = np.array(data)\n",
    "    \n",
    "    gray = []\n",
    "    cvtimg = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "    gray.append(cvtimg)\n",
    "    gray=np.array(gray)\n",
    "    \n",
    "    MOUTH_OUTLINE_POINTS = list(range(48, 61))  \n",
    "    MOUTH_INNER_POINTS = list(range(61, 68))\n",
    "\n",
    "    #defines the landmarks for the Mouth Outline and the inner mouth points  \n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "    #faceCascade is defined here, cascPath which is user supplied is the param  \n",
    "\n",
    "    predictor = dlib.shape_predictor(PREDICTOR_PATH)  \n",
    "    \n",
    "    face = faceCascade.detectMultiScale(gray[0], scaleFactor=1.05, minNeighbors=5, minSize=(100,100))\n",
    "    print(\"hello\")\n",
    "    print(\"Found {0} faces!\".format(len(face)))\n",
    "    \n",
    "    for (x, y, w, h) in face:  \n",
    "        dlib_rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))  \n",
    "\n",
    "        landmarks = np.matrix([[p.x, p.y]  \n",
    "              for p in predictor(image, dlib_rect).parts()])  \n",
    "\n",
    "        landmarks_display = landmarks[MOUTH_OUTLINE_POINTS + MOUTH_INNER_POINTS]\n",
    "\n",
    "        highX = 0\n",
    "        lowX = 1000\n",
    "        highY = 0\n",
    "        lowY = 1000\n",
    "\n",
    "        for idx, point in enumerate(landmarks_display):  \n",
    "            pos = (point[0, 0], point[0, 1])  \n",
    "            #cv2.circle(image, pos, 2, color=(0, 0, 255), thickness=-1)\n",
    "            if (pos[0] > highX):\n",
    "                highX = pos[0]\n",
    "            if (pos[0] < lowX):\n",
    "                lowX = pos[0]\n",
    "            if (pos[1] > highY):\n",
    "                highY = pos[1]\n",
    "            if (pos[1] < lowY):\n",
    "                lowY = pos[1]\n",
    "        #print (lowX, lowY, highX, highY)\n",
    "\n",
    "\n",
    "        CONSTANT_FACTOR = 0.325\n",
    "        delta_x = highX-lowX\n",
    "        delta_y = highY - lowY\n",
    "        low_x_adj = lowX - int(delta_x * CONSTANT_FACTOR)\n",
    "        high_x_adj = highX + int(delta_x * CONSTANT_FACTOR)\n",
    "        low_y_adj = lowY - int(delta_y * 0.2)\n",
    "        high_y_adj = highY + int(delta_y * CONSTANT_FACTOR)\n",
    "        crop_img = image[low_y_adj:high_y_adj,low_x_adj:high_x_adj]\n",
    "        cv2.imwrite(\"/home/akansha/Desktop/nor/Cropped_Mouth\"+str(count)+\".jpg\", crop_img)\n",
    "        #cv2.imshow(\"Cropped_Mouth.jpg\", crop_img)\n",
    "        #print(delta_x,delta_y,low_y_adj,high_y_adj,low_x_adj,high_x_adj)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Found 1 faces!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Everything is imported here\n",
    "\n",
    "folderpath = \"/home/akansha/Desktop/nor/\"#NEURAL_NETWORK/drowsiness_detection/dataset/mouth/yawn/yawn/\"\n",
    "cascPath = \"/home/akansha/Desktop/haarcascade_frontalface_default.xml\"\n",
    "PREDICTOR_PATH = \"/home/akansha/Desktop/shape_predictor_68_face_landmarks.dat\" \n",
    "\n",
    "#user supplies the folderpath and cascpath in a terminal/command prompt\n",
    "#predictor_path is already set\n",
    "\n",
    "imageformat = \".jpg\"\n",
    "path = folderpath\n",
    "imfilelist = [os.path.join(path,f) for f in os.listdir(path) if f.endswith(imageformat)]\n",
    "#print(len(imfilelist))\n",
    "#only images with \".tif\" extensions in the folder interest us, we create a\n",
    "#list with paths to those images    \n",
    "count = 0\n",
    "for IMG in imfilelist:\n",
    "    image = cv2.imread(IMG) #this for-loop iterates through images we need\n",
    "    #print(len(image))\n",
    "    mouth_extraction(image,count)\n",
    "    count=count+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
